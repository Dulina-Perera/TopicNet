# backend/app/services/summarize.py

# %%
import os

from numpy import ndarray
from openai import OpenAI
from openai.types.chat.chat_completion import ChatCompletion
from openai.types.chat.chat_completion_message import ChatCompletionMessage
from scipy.sparse import csr_matrix
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from transformers import pipeline, SummarizationPipeline
from typing import List, Tuple

# %%
summarizer: SummarizationPipeline = pipeline('summarization')

# %%
def chunk_text(
  text: str,
  max_chunk_size: int = 1000
) -> List[str]:
  '''
	Split the text into smaller chunks based on the maximum chunk size.
	Args:
		text (str): The input text to be split.
		max_chunk_size (int): The maximum size of each chunk.
	Returns:
		List[str]: A list of text chunks.
  '''
  words: List[str] = text.split()
  chunks: List[str] = []

  current_chunk: List[str] = []
  current_length: int = 0

  for word in words:
    if current_length + len(word) + 1 <= max_chunk_size:
      current_chunk.append(word)
      current_length += len(word) + 1
    else:
      chunks.append(' '.join(current_chunk))
      current_chunk = [word]
      current_length = len(word) + 1

  if current_chunk:
    chunks.append(' '.join(current_chunk))

  return chunks


def summarize_text(
  text: str,
  meta_title: str,
	max_chunk_size: int = 1000
) -> Tuple[str, str]:
	chunks: List[str] = chunk_text(text, max_chunk_size)

	summaries: List[str] = [summarizer(chunk, max_length=200, min_length=30, do_sample=False)[0]['summary_text'] for chunk in chunks]

	intermediate_summary: str = ' '.join(summaries)
	final_summary: str = summarizer(intermediate_summary, max_length=200, min_length=30, do_sample=False)[0]['summary_text']

	vectorizer: CountVectorizer = CountVectorizer(stop_words='english')
	transformer: TfidfTransformer = TfidfTransformer()

	X: csr_matrix = vectorizer.fit_transform([final_summary])
	tfidf_matrix: csr_matrix = transformer.fit_transform(X)
	feature_names: ndarray = vectorizer.get_feature_names_out()

	sorted_indices: ndarray = tfidf_matrix.toarray().sum(axis=0).argsort()[::-1]
	top_terms: List[str] = [feature_names[i] for i in sorted_indices[:5]]
	topic: str = '-'.join(top_terms)

	prompt: str = (
  	f"The following is a summary of a document:\n\n{final_summary}\n\n"
		f"The title extracted from the document is: {meta_title}\n\n"
		f"The title generated by topic modeling is: {topic}\n\n"
  	f"Please generate a more detailed and refined topic, and then write an enhanced content summary based on this information.\n\n"
  	f"Format your response as follows:\n"
  	f"Topic: <Your generated topic>\n"
  	f"Content Summary: <Your generated content summary>"
	)

	client: OpenAI = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

	response: ChatCompletion = client.chat.completions.create(
  	model="gpt-4o-mini",
  	messages=[
    	{"role": "system", "content": "You are a helpful assistant."},
    	{"role": "user", "content": prompt}
  	],
  	max_tokens=500,
  	temperature=0.7
	)

	generated_text: str = response.choices[0].message.content

	lines: List[str] = generated_text.split('\n')
	generated_topic: str = ""
	generated_content_summary: str = ""

	for line in lines:
		if line.startswith("Topic:"):
			generated_topic = line[len("Topic: "):].strip()
		elif line.startswith("Content Summary:"):
			generated_content_summary = line[len("Content Summary: "):].strip()

	return generated_topic, generated_content_summary
